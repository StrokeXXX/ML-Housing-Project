# Housing Price Prediction - MLflow Tracking
# Notebook pour l'entra√Ænement avec suivi des exp√©riences

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import mlflow
import mlflow.sklearn
from mlflow.models.signature import infer_signature
import warnings
warnings.filterwarnings('ignore')

# Configuration MLflow
mlflow.set_experiment("housing-price-prediction")

def load_and_explore_data():
    """Charge et explore le dataset California Housing"""
    print("üìä Chargement des donn√©es...")
    
    # Charger les donn√©es
    housing = fetch_california_housing()
    X = pd.DataFrame(housing.data, columns=housing.feature_names)
    y = pd.Series(housing.target, name='MedHouseVal')
    
    print(f"Shape des donn√©es: {X.shape}")
    print(f"Features: {list(X.columns)}")
    
    # Informations de base
    df = pd.concat([X, y], axis=1)
    print("\nüìà Statistiques descriptives:")
    print(df.describe())
    
    # V√©rifier les valeurs manquantes
    print(f"\n‚ùå Valeurs manquantes: {df.isnull().sum().sum()}")
    
    return X, y, df

def create_visualizations(df):
    """Cr√©e des visualisations exploratoires"""
    print("üìä Cr√©ation des visualisations...")
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # Distribution du prix
    axes[0,0].hist(df['MedHouseVal'], bins=50, alpha=0.7)
    axes[0,0].set_title('Distribution des Prix')
    axes[0,0].set_xlabel('Prix M√©dian ($100k)')
    
    # Relation prix vs revenus
    axes[0,1].scatter(df['MedInc'], df['MedHouseVal'], alpha=0.5)
    axes[0,1].set_title('Prix vs Revenus M√©dians')
    axes[0,1].set_xlabel('Revenus M√©dians')
    axes[0,1].set_ylabel('Prix M√©dian')
    
    # Heatmap des corr√©lations
    corr_matrix = df.corr()
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[1,0])
    axes[1,0].set_title('Matrice de Corr√©lation')
    
    # Distribution de l'√¢ge des maisons
    axes[1,1].hist(df['HouseAge'], bins=30, alpha=0.7)
    axes[1,1].set_title('Distribution √Çge des Maisons')
    axes[1,1].set_xlabel('√Çge des Maisons')
    
    plt.tight_layout()
    plt.savefig('data_exploration.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return 'data_exploration.png'

def train_linear_model(X_train, X_test, y_train, y_test, run_name="linear_regression"):
    """Entra√Æne un mod√®le de r√©gression lin√©aire avec MLflow tracking"""
    
    with mlflow.start_run(run_name=run_name):
        print(f"üöÄ Entra√Ænement: {run_name}")
        
        # Preprocessing
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Mod√®le
        model = LinearRegression()
        model.fit(X_train_scaled, y_train)
        
        # Pr√©dictions
        y_pred = model.predict(X_test_scaled)
        
        # M√©triques
        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        # Log des param√®tres
        mlflow.log_param("model_type", "LinearRegression")
        mlflow.log_param("scaling", "StandardScaler")
        mlflow.log_param("train_size", len(X_train))
        mlflow.log_param("test_size", len(X_test))
        
        # Log des m√©triques
        mlflow.log_metric("mse", mse)
        mlflow.log_metric("rmse", rmse)
        mlflow.log_metric("mae", mae)
        mlflow.log_metric("r2_score", r2)
        
        # Log du mod√®le avec signature
        signature = infer_signature(X_train, y_pred)
        mlflow.sklearn.log_model(
            model, 
            "model",
            signature=signature,
            input_example=X_train.iloc[:5]
        )
        
        # Log du preprocessing
        mlflow.sklearn.log_model(scaler, "scaler")
        
        print(f"   RMSE: {rmse:.4f}")
        print(f"   R¬≤: {r2:.4f}")
        print(f"   MAE: {mae:.4f}")
        
        return model, scaler, {"rmse": rmse, "r2": r2, "mae": mae}

def train_random_forest(X_train, X_test, y_train, y_test, run_name="random_forest"):
    """Entra√Æne un Random Forest avec hyperparameter tuning"""
    
    with mlflow.start_run(run_name=run_name):
        print(f"üå≥ Entra√Ænement: {run_name}")
        
        # Param√®tres √† tester
        param_grid = {
            'n_estimators': [50, 100, 200],
            'max_depth': [10, 20, None],
            'min_samples_split': [2, 5],
            'min_samples_leaf': [1, 2]
        }
        
        # GridSearch
        rf = RandomForestRegressor(random_state=42)
        grid_search = GridSearchCV(
            rf, 
            param_grid, 
            cv=3, 
            scoring='neg_mean_squared_error',
            n_jobs=-1,
            verbose=1
        )
        
        grid_search.fit(X_train, y_train)
        best_model = grid_search.best_estimator_
        
        # Pr√©dictions
        y_pred = best_model.predict(X_test)
        
        # M√©triques
        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        # Log des meilleurs param√®tres
        mlflow.log_param("model_type", "RandomForestRegressor")
        for param, value in grid_search.best_params_.items():
            mlflow.log_param(param, value)
        
        mlflow.log_param("train_size", len(X_train))
        mlflow.log_param("test_size", len(X_test))
        
        # Log des m√©triques
        mlflow.log_metric("mse", mse)
        mlflow.log_metric("rmse", rmse)
        mlflow.log_metric("mae", mae)
        mlflow.log_metric("r2_score", r2)
        mlflow.log_metric("cv_score", -grid_search.best_score_)
        
        # Feature importance
        feature_importance = pd.DataFrame({
            'feature': X_train.columns,
            'importance': best_model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        # Graphique feature importance
        plt.figure(figsize=(10, 6))
        plt.bar(feature_importance['feature'], feature_importance['importance'])
        plt.title('Feature Importance - Random Forest')
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # Log du mod√®le
        signature = infer_signature(X_train, y_pred)
        mlflow.sklearn.log_model(
            best_model, 
            "model",
            signature=signature,
            input_example=X_train.iloc[:5]
        )
        
        # Log des artifacts
        mlflow.log_artifact('feature_importance.png')
        
        print(f"   RMSE: {rmse:.4f}")
        print(f"   R¬≤: {r2:.4f}")
        print(f"   MAE: {mae:.4f}")
        print(f"   Meilleurs param√®tres: {grid_search.best_params_}")
        
        return best_model, {"rmse": rmse, "r2": r2, "mae": mae}

def compare_models_results(results):
    """Compare les r√©sultats des diff√©rents mod√®les"""
    print("\nüìä Comparaison des Mod√®les:")
    print("-" * 50)
    
    comparison_df = pd.DataFrame(results).T
    print(comparison_df.round(4))
    
    # Graphique de comparaison
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    metrics = ['rmse', 'r2', 'mae']
    titles = ['RMSE (plus bas = mieux)', 'R¬≤ (plus haut = mieux)', 'MAE (plus bas = mieux)']
    
    for i, (metric, title) in enumerate(zip(metrics, titles)):
        comparison_df[metric].plot(kind='bar', ax=axes[i], color=['skyblue', 'lightcoral'])
        axes[i].set_title(title)
        axes[i].set_ylabel(metric.upper())
        axes[i].tick_params(axis='x', rotation=45)
    
    plt.tight_layout()
    plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return 'model_comparison.png'

def main():
    """Fonction principale d'ex√©cution"""
    print("üè† Housing Price Prediction - MLflow Tracking")
    print("=" * 60)
    
    # 1. Charger et explorer les donn√©es
    X, y, df = load_and_explore_data()
    
    # 2. Cr√©er les visualisations
    viz_file = create_visualizations(df)
    
    # 3. Split train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    print(f"\nüîÑ Split des donn√©es:")
    print(f"   Train: {X_train.shape[0]} √©chantillons")
    print(f"   Test: {X_test.shape[0]} √©chantillons")
    
    # 4. Entra√Æner les mod√®les
    results = {}
    
    # R√©gression lin√©aire
    linear_model, scaler, linear_results = train_linear_model(
        X_train, X_test, y_train, y_test
    )
    results['Linear Regression'] = linear_results
    
    # Random Forest
    rf_model, rf_results = train_random_forest(
        X_train, X_test, y_train, y_test
    )
    results['Random Forest'] = rf_results
    
    # 5. Comparer les r√©sultats
    comparison_file = compare_models_results(results)
    
    # 6. Recommandations
    best_model_name = min(results.keys(), key=lambda x: results[x]['rmse'])
    print(f"\nüèÜ Meilleur mod√®le: {best_model_name}")
    print(f"   RMSE: {results[best_model_name]['rmse']:.4f}")
    print(f"   R¬≤: {results[best_model_name]['r2']:.4f}")
    
    print(f"\n‚úÖ Exp√©riences enregistr√©es dans MLflow!")
    print(f"   Lancez 'mlflow ui' pour voir les r√©sultats")
    
    return results

# Ex√©cution
if __name__ == "__main__":
    results = main()
